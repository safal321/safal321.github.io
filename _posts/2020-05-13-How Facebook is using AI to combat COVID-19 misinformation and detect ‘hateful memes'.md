<img src='https://cdn.vox-cdn.com/thumbor/lHTd8ABvuVZ0AWBcAaeSYp2lblA=/0x0:2040x1360/1200x800/filters:focal(831x690:1157x1016)/cdn.vox-cdn.com/uploads/chorus_image/image/66785966/jbareham_180405_1777_facebook_0003.0.jpg' width='700px' /><br/>
Facebook on Monday released a new report detailing how it uses a combination of artificial intelligence and human fact-checkers and moderators to enforce its community standards. The report — called the Community Standards Enforcement Report, which usually encompasses data and findings from the prior three to six months — has a large focus on AI this time around and the progress Facebook is relying more on software instead of people, given the extreme toll the job can take on human moderators.
<a href='https://www.theverge.com/2020/5/12/21254960/facebook-ai-moderation-covid-19-coronavirus-hateful-memes-hate-speech'> Source <a/>