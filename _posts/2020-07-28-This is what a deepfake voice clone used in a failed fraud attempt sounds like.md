<img src='https://cdn.vox-cdn.com/thumbor/oHoGH4UgbOpVd4SXkEv-_HAC-Kw=/0x0:2040x1360/1200x800/filters:focal(857x517:1183x843)/cdn.vox-cdn.com/uploads/chorus_image/image/67112457/DSCF2964.0.jpg' width='700px' /><br/>
One of the stranger applications of deepfakes — AI technology used to manipulate audiovisual content — is the audio deepfake scam. Hackers use machine learning to clone someone's voice and then combine that voice clone with social engineering techniques to convince people to move money where it shouldn't be. Such scams have been successful in the past, but how good are the voice clones being used in these attacks? We've never actually heard the audio from a deepfake scam — until now.
<a href='https://www.theverge.com/2020/7/27/21339898/deepfake-audio-voice-clone-scam-attempt-nisos'> Source <a/>